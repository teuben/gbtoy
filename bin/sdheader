#! /usr/bin/env python

__doc__ = """
   Inspect an SDFITS (sometimes called SDF) header on standards conformation
   An SDFITS files is just a Multi-Extension FITS (MEF) files, which extensions
   (it can have 1 or more) must have extention name  'SINGLE DISH'

   standard!  what standard?

   Also note that Harvey's 1995 sdfits document is "somewhat" out of date (e.g. y2k, FREQRES)

   see also    https://safe.nrao.edu/wiki/bin/view/Main/SdfitsDetails   (2017, really 2007)
               https://casa.nrao.edu/aips2_docs/notes/236/node14.html   (2006)

   This code also attempts to "register' all known header variables (virtual as well as full)
   but it would be better to wrap this into a class in the final GBT eco system.

   Optionally column names can be given, and their uniq values are reported.
"""


import os
import sys
import numpy as np
from astropy.io import fits
# -------------------------------------------------  deal with command line

if len(sys.argv) == 1:
    print("Usage: %s sdfitsfile [cols]" % sys.argv[0])
    print(__doc__)
    sys.exit(1)

sdfits=sys.argv[1]
if not os.path.exists(sdfits):
    print("File does not exist: ",sdfits)
    sys.exit(1)

check_cols = sys.argv[2:]    

# -------------------------------------------------   script can start

# fits known non-SDFITS 
h_fits1 = ['SIMPLE',        # always T
           'BITPIX',        # always 8 for bintable
           'NAXIS',         # always 2 for bintable, 0 for the primary HDU
           'NAXIS1',        # width of table (sum of all columns)
           'NAXIS2',        # number of rows
           'EXTEND',        # always T
           'COMMENT',
           'HISTORY',
           'DATE',          # see also DATE-OBS below
           'ORIGIN',        # 'NRAO Green Bank'
           'INSTRUME',      #
           'SDFITVER',      # 
           'FITSVER',       # GUIDEVER has also been seen
           'END',
           'XTENSION',      # 'BINTABLE'
           'EXTNAME',       # 'SINGLE DISH'
           'PCOUNT',        # 0
           'GCOUNT',        # 1
           'TFIELDS',       # number of fields
          ]

# fits indexed keywords
h_fits2 = ['TTYPE',
           'TFORM',
           'TUNIT',
           'TDIM',
          ]   

# core keywords (required)
h_core = ['BANDWID',      #-
          'DATA',
          'DATE-OBS',     #-  yipes, DATE_OBS is also seen
          'EXPOSURE',     #-  
          'DURATION',     # is this core now?
          'OBJECT',       #-
          'TELESCOP',     #-  'NRAO_GBT'
          'TSYS',         #-
                          # FREQRES ?
                          # TIME is old, now DATA-OBS has the 2005-06-28T08:56:38.00 type notation
          ]

# shared keywords
h_shared = ['OBSERVER',
            'OBSID',      # https://safe.nrao.edu/wiki/bin/view/GB/Software/ModificationRequest8Q312    (also SCANID, PROCTYPE)
            'PROJID',
            'SCAN',
            'OBSMODE',
            'MOLECULE',
            'TRANSITI',
            'FRONTEND',  #-
            'BACKEND',   #-
            'TEMPSCAL',
            'TCAL',
            'THOT',
            'TCOLD',
            'TRX',
            'FREQRES',    #  was core in 1995, 2000 says shared
            'VELDEF',
            'VFRAME',     # where is VCORR
            'RVSYS',      # where is VCORR
            'OBSFREQ',
            'IMAGFREQ',
            'RESTFREQ',
            'TIMESYS',    # ?
            'LST',
            'AZIMUTH',
            'ELEVATIO',
            'TAU',
            'TAUIMAGE',
            'TAUZENIT',
            'BEAMEFF',
            'APEREFF',
            'ETAL',
            'ETAFSS',
            'ANTGAIN',
            'BMAJ',
            'BMIN',
            'BPA',
            'SITELONG',
            'SITELAT',
            'SITEELEV',
            'HUMIDITY',
            'DEWPOINT',
            'TAMBIENT',
            'PRESSURE',
            'WINDSPEE',
            'WINDDIRE',
            ]

# site specific
h_gbt =    ['EQUINOX',      # EPOCH?
            'RADECSYS',     # 2017
            'TRGTLONG',     # 2017
            'TRGTLAT',      # 2017
            'SAMPLER',
            'FEED',
            'SRFEED',
            'BEAMXOFF',
            'BEAMEOFF',
            'SUBREF_STATE',  # 2017
            'SIDEBAND',
            'PROCSEQN',      # scan sequence number
            'PROCSIZE',      # number of scans in procedure
            'LASTON',
            'LASTOFF',
            'TIMESTAMP',     # 2017     "YYYY_MM_DD_HH:MM:SS".
            'VELOCITY',
            'ZEROCHAN',      # 2017
            'SIG',
            'CAL',           # "T" means it's ON, 'F' it's OFF
            'CALTYPE',       # 2017    LOW or HIGH
            'DOPFREQ',       # EDGE 2013
            'RADESYS',       # EDGE, note there is also a RADECSYS !!!
            'FEEDXOFF',      # EDGE, note there is also a BEAMXOFF,BEAMEOFF
            'FEEDEOFF',      # EDGE
            'PROCSCAN',      # EDGE
            'PROCTYPE',      # EDGE
            'QD_XEL',        # EDGE
            'QD_EL',         # EDGE
            'QD_BAD',        # EDGE
            'QD_METHOD',     # EDGE
            'FOFFREF1',      # EDGE
            'CALPOSITION',   # EDGE
            'IFNUM',         # EDGE 2013
            'PLNUM',         # EDGE 2013
            'FDNUM',         # EDGE 2013
            'INT',           # EDGE .
            'NSAVE',         # EDGE .
            'TWARM',         # 4mm
            'TCOLD',         # 4mm
            'CALPOSITION',   # 4mm   (internally called POSITION)
            'ADCSAMPF',      # argus?
            'VSPDELT',       # argus?
            'VSPRVAL',       # argus?
            'VSPRPIX',       # argus?
            ]

h_parkes =  ['CYCLE',        # Mark Calabretta:
             'BEAM',         #   considers these critical
             'IF',           #   presumably for Parkes?
            ]

h_arecibo = []               # rumors on some WCS usages

# Tom Kuiper kuiper at jpl.nasa.gov - DSN spectroscopic runs to produce compatible SDFITS files
# DSS-28 can simultaneously have both polarizations at, for example, 3, 6, 9 and 12 GHz.
#
#


h_sdfits = h_core + h_shared + h_gbt


hdu = fits.open(sdfits)
print(hdu.info())


print("SDFITS: There are %2d known CORE   columns" % len(h_core))
print("SDFITS: There are %2d known SHARED columns" % len(h_shared))
print("SDFITS: There are %2d known GBT    columns" % len(h_gbt))

def first_digit_index(key):
    for i, c in enumerate(key):
        if c.isdigit():
            return i
    return -1

def inta1(value):
    """  converts strings such as "123BLA' to an integer (123)
    """
    # add 'X' to make sure strings such as "123" also convert
    for i, c in enumerate(value+'X'):
        if not c.isdigit():
            break
    return int(value[:i])

def inta2(value):
    """  converts strings such as "BLA123' to an integer (123)
    """
    for i, c in enumerate(value):
        if c.isdigit():
            return int(value[i:])
    return -1
    
    
header1 = hdu[0].header
for h in header1.keys():
    if h not in h_fits1:
        if h in h_sdfits:
            print('SDFITS:   Pri header',h)
        else:
            print('UNKNOWN1: Pri header',h)

          
for i in range(1,len(hdu)):
    header2 = hdu[i].header
    extname = header2['EXTNAME']
    tdim = None
    print("HDU-%d %s" % (i+1, extname))
    if extname != 'SINGLE DISH':
        print('%s is not a SINGLE DISH extension - skipping' % extname)
        continue
    nrows = header2['NAXIS2']
    ncols = header2['TFIELDS']
    # check the keywords (some may be virtual columns)
    for h in header2.keys():
        if header2[h] == 'DATA':
            h1 = h.replace('TTYPE','TFORM')
            h2 = h.replace('TTYPE','TFORM')
            i1 = inta2(h)
            tdim = 'TDIM%d' % i1
            nchan = inta1(header2[h1])
        if h not in h_fits1:
            if h in h_sdfits:
                print('SDFITS:  Ext header',h)
            else:
                hd = first_digit_index(h)
                if hd < 0:
                    print('UNKNOWN1: Ext header',h)
                elif h[:hd] not in h_fits2:
                    print('UNKNOWN2: Ext header',h)            
                # no need to show the indexed keywords
    for colname in check_cols:
        colvals = hdu[i].data[:][colname]
        print('%s: %s' % (colname,repr(list(np.unique(colvals)))))
    # check the column names (via TTYPEnnn)
    for j in range(ncols):
        key = 'TTYPE%d' % (j+1)
        h = header2[key]
        if h not in h_sdfits:
            print('UNKNOWN3: Ext header',h)
    if tdim != None:
        if tdim in header2:
            datadim = header2[tdim]
        else:
            datadim = hdu[i].data[0][tdim]
        # @TODO what if neither set?
    else:
        datadim = ""
    date_0 = hdu[i].data[0]['DATE-OBS']
    date_1 = hdu[i].data[nrows-1]['DATE-OBS']    
    print("HDU-%d SINGLE DISH %d rows x %d cols x %d chans %s" % (i+1,nrows,ncols,nchan,datadim))
    print("DATE-OBS:  %s - %s" % (date_0,date_1))
