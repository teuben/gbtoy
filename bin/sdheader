#! /usr/bin/env python
#
#   inspect an SDFITS (sometimes called SDF) header on standards conformation
#
#   standard!  what standard?
#
#   note that Harvey's 1995 is "somewhat" out of date (e.g. y2k, FREQRES)
#
#   see also    https://safe.nrao.edu/wiki/bin/view/Main/SdfitsDetails   (2017, really 2007)
#               https://casa.nrao.edu/aips2_docs/notes/236/node14.html   (2006)



import os
import sys
import numpy as np
from astropy.io import fits
# -------------------------------------------------  deal with command line

if len(sys.argv) == 1:
    print("Usage: %s sdfitsfile" % sys.argv[0])
    sys.exit(1)

sdfits=sys.argv[1]
if not os.path.exists(sdfits):
    print("File does not exist: ",sdfits)
    sys.exit(1)

# -------------------------------------------------   script can start

# fits known non-SDFITS 
h_fits1 = ['SIMPLE',
           'BITPIX',
           'NAXIS',
           'NAXIS1',
           'NAXIS2',
           'EXTEND',
           'COMMENT',
           'HISTORY',
           'DATE',
           'ORIGIN',
           'INSTRUME',
           'SDFITVER',
           'FITSVER',       # GUIDEVER has also been seen
           'END',
           'XTENSION',
           'EXTNAME',
           'PCOUNT',
           'GCOUNT',
           'TFIELDS',
          ]

# fits indexed keywords
h_fits2 = ['TTYPE',
           'TFORM',
           'TUNIT',
           'TDIM',
          ]   

# core keywords (required)
h_core = ['BANDWID',      #-
          'DATA',
          'DATE-OBS',     #-
          'EXPOSURE',     #-  what about DURATION
          'OBJECT',       #-
          'TELESCOP',     #-
          'TSYS',         #-
                          # FREQRES ?
                          # TIME is old, now DATA-OBS has the 2005-06-28T08:56:38.00 type notation
          ]

# shared keywords
h_shared = ['OBSERVER',
            'OBSID',
            'PROJID',
            'SCAN',
            'OBSMODE',
            'MOLECULE',
            'TRANSITI',
            'FRONTEND',  #-
            'BACKEND',   #-
            'TEMPSCAL',
            'TCAL',
            'THOT',
            'TCOLD',
            'TRX',
            'FREQRES',    #  was core in 1995, 2000 says shared
            'VELDEF',
            'VFRAME',     # where is VCORR
            'RVSYS',      # where is VCORR
            'OBSFREQ',
            'IMAGFREQ',
            'RESTFREQ',
            'TIMESYS',    # ?
            'LST',
            'AZIMUTH',
            'ELEVATIO',
            'TAU',
            'TAUIMAGE',
            'TAUZENIT',
            'BEAMEFF',
            'APEREFF',
            'ETAL',
            'ETAFSS',
            'ANTGAIN',
            'BMAJ',
            'BMIN',
            'BPA',
            'SITELONG',
            'SITELAT',
            'SITEELEV',
            'HUMIDITY',
            'DEWPOINT',
            'TAMBIENT',
            'PRESSURE',
            'WINDSPEE',
            'WINDDIRE',
            ]

# site specific
h_gbt =    ['EQUINOX',      # EPOCH?
            'RADECSYS',     # 2017
            'TRGTLONG',     # 2017
            'TRGTLAT',      # 2017
            'SAMPLER',
            'FEED',
            'SRFEED',
            'BEAMXOFF',
            'BEAMEOFF',
            'SUBREF_STATE',  # 2017
            'SIDEBAND',
            'PROCSEQN',      # scan sequence number
            'PROCSIZE',      # number of scans in procedure
            'LASTON',
            'LASTOFF',
            'TIMESTAMP',     # 2017     "YYYY_MM_DD_HH:MM:SS".
            'VELOCITY',
            'ZEROCHAN',      # 2017
            'SIG',
            'CAL',           # "T" means it's ON, 'F' it's OFF
            'CALTYPE',       # 2017    LOW or HIGH
            ]

h_parkes =  ['CYCLE',        # Mark Calabretta:
             'BEAM',         #   considers these critical
             'IF',           #   presumably for Parkes?
            ]

h_arecibo = []               # rumors on some WCS usages


h_sdfits = h_core + h_shared + h_gbt


hdu = fits.open(sdfits)
print("Found %d HDU's" % len(hdu))


print("There are %2d known CORE   columns" % len(h_core))
print("There are %2d known SHARED columns" % len(h_shared))
print("There are %2d known GBT    columns" % len(h_gbt))

def first_digit(key):
    for i, c in enumerate(key):
        if c.isdigit():
            return i
    return -1
    
header1 = hdu[0].header
for h in header1.keys():
    if h not in h_fits1:
        if h in h_sdfits:
            print('SDFITS:  Primary header',h)
        else:
            print('UNKNOWN: Primary header',h)
          
for i in range(1,len(hdu)):
    header2 = hdu[i].header
    extname = header2['EXTNAME']    
    print("HDU-%d %s" % (i+1, extname))
    if extname != 'SINGLE DISH':
        print('%s is not a SINGLE DISH extension - skipping' % extname)
        continue
    nrows = header2['NAXIS2']
    ncols = header2['TFIELDS']
    print("SINGLE DISH %d rows x %d cols" % (nrows,ncols))
    for h in header2.keys():
        if h not in h_fits1:
            if h in h_sdfits:
                print('SDFITS:  ext header',h)
            else:
                hd = first_digit(h)
                if hd < 0:
                    print('UNKNOWN1: ext header',h)
                elif h[:hd] not in h_fits2:
                    print('UNKNOWN2: ext header',h)            
                # no need to show the indexed keywords


